{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `/global/u2/r/raye/julia-hpc-tutorial-juliacon25`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSgoDg8fFyEp",
    "outputId": "baa455e0-dcfe-4a57-ae91-674180d5d459"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Polyester ────────── v0.7.18\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Unrolled ─────────── v0.1.5\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ThreadingUtilities ─ v0.5.5\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StrideArraysCore ─── v0.5.7\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ArrayInterface ───── v7.19.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m AcceleratedKernels ─ v0.3.1\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `/global/u2/r/raye/julia-hpc-tutorial-juliacon25/Project.toml`\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[6a4ca0a5] \u001b[39m\u001b[92m+ AcceleratedKernels v0.3.1\u001b[39m\n",
      " \u001b[90m[79e6a3ab] \u001b[39m\u001b[92m+ Adapt v4.3.0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[a9b6321e] \u001b[39m\u001b[92m+ Atomix v0.1.0\u001b[39m\n",
      "  \u001b[90m[4e3cecfd] \u001b[39m\u001b[92m+ ImageShow v0.3.8\u001b[39m\n",
      "  \u001b[90m[5da4648a] \u001b[39m\u001b[92m+ NVTX v1.0.0\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `/global/u2/r/raye/julia-hpc-tutorial-juliacon25/Manifest.toml`\n",
      " \u001b[90m[6a4ca0a5] \u001b[39m\u001b[92m+ AcceleratedKernels v0.3.1\u001b[39m\n",
      "  \u001b[90m[dce04be8] \u001b[39m\u001b[92m+ ArgCheck v2.5.0\u001b[39m\n",
      "  \u001b[90m[4fba245c] \u001b[39m\u001b[92m+ ArrayInterface v7.19.0\u001b[39m\n",
      "  \u001b[90m[62783981] \u001b[39m\u001b[92m+ BitTwiddlingConvenienceFunctions v0.1.6\u001b[39m\n",
      "  \u001b[90m[2a0fbf3d] \u001b[39m\u001b[92m+ CPUSummary v0.2.6\u001b[39m\n",
      "  \u001b[90m[fb6a15b2] \u001b[39m\u001b[92m+ CloseOpenIntervals v0.1.13\u001b[39m\n",
      "  \u001b[90m[f70d9fcc] \u001b[39m\u001b[92m+ CommonWorldInvalidations v1.0.0\u001b[39m\n",
      "  \u001b[90m[adafc99b] \u001b[39m\u001b[92m+ CpuId v0.3.1\u001b[39m\n",
      "  \u001b[90m[615f187c] \u001b[39m\u001b[92m+ IfElse v0.1.1\u001b[39m\n",
      "  \u001b[90m[4e3cecfd] \u001b[39m\u001b[92m+ ImageShow v0.3.8\u001b[39m\n",
      "  \u001b[90m[10f19ff3] \u001b[39m\u001b[92m+ LayoutPointers v0.1.17\u001b[39m\n",
      "  \u001b[90m[d125e4d3] \u001b[39m\u001b[92m+ ManualMemory v0.1.8\u001b[39m\n",
      "  \u001b[90m[f517fe37] \u001b[39m\u001b[92m+ Polyester v0.7.18\u001b[39m\n",
      "  \u001b[90m[1d0040c9] \u001b[39m\u001b[92m+ PolyesterWeave v0.2.2\u001b[39m\n",
      "  \u001b[90m[94e857df] \u001b[39m\u001b[92m+ SIMDTypes v0.1.0\u001b[39m\n",
      "  \u001b[90m[aedffcd0] \u001b[39m\u001b[92m+ Static v1.2.0\u001b[39m\n",
      "  \u001b[90m[0d7ed370] \u001b[39m\u001b[92m+ StaticArrayInterface v1.8.0\u001b[39m\n",
      "  \u001b[90m[7792a7ef] \u001b[39m\u001b[92m+ StrideArraysCore v0.5.7\u001b[39m\n",
      "  \u001b[90m[8290d209] \u001b[39m\u001b[92m+ ThreadingUtilities v0.5.5\u001b[39m\n",
      "  \u001b[90m[9602ed7d] \u001b[39m\u001b[92m+ Unrolled v0.1.5\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m have new versions available and may be upgradable.\n",
      "\u001b[92m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "  17079.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mThreadingUtilities\u001b[39m\n",
      "  17349.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mUnrolled\u001b[39m\n",
      "  17260.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface\u001b[39m\n",
      "ImageShow ms\u001b[32m  ✓ \u001b[39m\n",
      "    646.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface → ArrayInterfaceGPUArraysCoreExt\u001b[39m\n",
      "    964.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface → ArrayInterfaceSparseArraysExt\u001b[39m\n",
      "    617.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface → ArrayInterfaceStaticArraysCoreExt\u001b[39m\n",
      "   1076.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface → ArrayInterfaceChainRulesCoreExt\u001b[39m\n",
      "   1386.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPolyesterWeave\u001b[39m\n",
      "   2315.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrayInterface\u001b[39m\n",
      "    880.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCloseOpenIntervals\u001b[39m\n",
      "   1573.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrayInterface → StaticArrayInterfaceOffsetArraysExt\u001b[39m\n",
      "   1166.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLayoutPointers\u001b[39m\n",
      "   1644.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrayInterface → StaticArrayInterfaceStaticArraysExt\u001b[39m\n",
      "   1433.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStrideArraysCore\u001b[39m\n",
      "   1419.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPolyester\u001b[39m\n",
      "   5776.6 ms\u001b[32m  ✓ \u001b[39mAcceleratedKernels\n",
      "  14682.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface → ArrayInterfaceCUDAExt\u001b[39m\n",
      "  18 dependencies successfully precompiled in 77 seconds. 433 already precompiled.\n"
     ]
    }
   ],
   "source": [
    "Pkg.add([\n",
    "    \"CUDA\",\n",
    "    \"KernelAbstractions\",\n",
    "    \"Atomix\",\n",
    "    \"AcceleratedKernels\",\n",
    "    \"BenchmarkTools\",\n",
    "    \"Adapt\",\n",
    "    \"NVTX\",\n",
    "    \"ImageShow\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJdnRZwNF2fh",
    "outputId": "3a36f4c1-e9e3-4957-c985-d9bf3882ba24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.11.4\n",
      "Commit 8561cc3d68d (2025-03-10 11:36 UTC)\n",
      "Build Info:\n",
      "  Official https://julialang.org/ release\n",
      "Platform Info:\n",
      "  OS: Linux (x86_64-linux-gnu)\n",
      "  CPU: 128 × AMD EPYC 7763 64-Core Processor\n",
      "  WORD_SIZE: 64\n",
      "  LLVM: libLLVM-16.0.6 (ORCJIT, znver3)\n",
      "Threads: 16 default, 0 interactive, 8 GC (on 128 virtual cores)\n",
      "Environment:\n",
      "  LD_LIBRARY_PATH = /global/common/software/nersc9/darshan/default/lib:/opt/nvidia/hpc_sdk/Linux_x86_64/24.5/math_libs/12.4/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/24.5/cuda/12.4/extras/CUPTI/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/24.5/cuda/12.4/extras/Debugger/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/24.5/cuda/12.4/nvvm/lib64:/opt/nvidia/hpc_sdk/Linux_x86_64/24.5/cuda/12.4/lib64:/opt/cray/pe/papi/7.1.0.2/lib64:/opt/cray/libfabric/1.20.1/lib64:/opt/cray/libfabric/default/lib64\n",
      "  JULIA_LOAD_PATH = :/global/common/software/nersc9/julia/environments/gnu.cray-mpich.cuda12.4\n",
      "  JULIA_SSL_CA_ROOTS_PATH = /etc/ssl/ca-bundle.pem\n",
      "  JULIA_NUM_THREADS = 16\n",
      "  JULIA_REVISE_POLL = 1\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ru_R_unVF8JR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling ParsersExt [f526588d-e68b-5dc5-a62e-ff9f36e48b1a] (cache misses: wrong dep version loaded (4))\n"
     ]
    }
   ],
   "source": [
    "using CUDA, KernelAbstractions, Adapt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eP-7j9lYMSrc"
   },
   "source": [
    "## A first GPU kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9to6RnQBMaWI",
    "outputId": "fa267f65-99fa-4c0a-c9a8-6a37b23464a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_cpu! (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function copy_cpu!(A, B)\n",
    "  for I in 1:length(A)\n",
    "    @inbounds A[I] = B[I]\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgeKBnvaMp_K",
    "outputId": "0374f71f-ce46-4735-fb20-ad2b486c6a87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function copy_kernel!(A, B)\n",
    "  I = @index(Global)\n",
    "  @inbounds A[I] = B[I]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-p6C7VlMtbv",
    "outputId": "0398c224-2b53-4bf0-eeb7-3ef91c64d766"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_ka! (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function copy_ka!(A, B)\n",
    "  backend = get_backend(A)\n",
    "  @assert size(A) == size(B)\n",
    "  @assert get_backend(B) == backend\n",
    "\n",
    "  kernel = copy_kernel!(backend)\n",
    "  kernel(A, B, ndrange = length(A))\n",
    "  return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mjt_75UzPWz3"
   },
   "outputs": [],
   "source": [
    "using CUDA: i32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xtUFmO4PFD6",
    "outputId": "5921503e-e062-4a83-f67d-8fbcefc426e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_kernel_cuda! (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function copy_kernel_cuda!(A, B)\n",
    "  I = (blockIdx().x-1i32) * blockDim().x + threadIdx().x\n",
    "  if I <= length(A)\n",
    "      @inbounds A[I] = B[I]\n",
    "  end\n",
    "  return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HykWeqPYM3O4",
    "outputId": "b0fd1838-8f57-4e50-eca9-287065589cec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy_cuda! (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function copy_cuda!(A, B)\n",
    "  kernel = @cuda launch=false copy_kernel_cuda!(A, B)\n",
    "  config = launch_configuration(kernel.fun)\n",
    "  threads = min(length(A), config.threads)\n",
    "  blocks = cld(length(A), threads)\n",
    "\n",
    "  kernel(A, B; threads, blocks)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IiQw4-ZsNX09"
   },
   "outputs": [],
   "source": [
    "B = rand(64_000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NomJoN_cN8j8"
   },
   "outputs": [],
   "source": [
    "let\n",
    "  A = similar(B)\n",
    "  copy_cpu!(A, B)\n",
    "  @assert A == B\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTn9RZViOK7E"
   },
   "source": [
    "Julia GPU ecosystem follows the motto: Compute follows Data\n",
    "\n",
    "So let's move our data to the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KeFIdqtoOVpn"
   },
   "outputs": [],
   "source": [
    "d_B = adapt(CuArray, B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mGdoaInOmG1",
    "outputId": "ea9e7eeb-785c-465c-be6c-55eeea8fc150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuArray{Float64, 1, CUDA.DeviceMemory}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(d_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CH-SW0koOHe7"
   },
   "outputs": [],
   "source": [
    "let\n",
    "  d_A = similar(d_B)\n",
    "  copy_cuda!(d_A, d_B)\n",
    "  @assert d_A == d_B\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKpr9veGPeJn"
   },
   "source": [
    "Note that Julia GPU Ecosystem, synchronizes the GPU on access. So we are launchign two GPU kernels here, first the copy, then the comparision and they are both executing asynchronously, but ordered with respect to each other.\n",
    "\n",
    "We then \"wait\" for the result of the comparision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xQawEsBoPdNx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling BenchmarkTools [6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf] (cache misses: wrong dep version loaded (4))\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVmA2-2XP81s",
    "outputId": "1fce7b1c-b8c8-49aa-de34-d93db72a26ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 7 evaluations per sample.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m4.164 μs\u001b[22m\u001b[39m … \u001b[35m 12.606 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m4.921 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m5.021 μs\u001b[22m\u001b[39m ± \u001b[32m802.313 ns\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m▅\u001b[39m█\u001b[39m▆\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▆\u001b[39m▆\u001b[39m▃\u001b[39m▁\u001b[39m▇\u001b[34m▇\u001b[39m\u001b[32m▄\u001b[39m\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▅\u001b[39m▃\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▄\u001b[39m▅\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▄\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m \u001b[39m█\n",
       "  4.16 μs\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      8.03 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m400 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m22\u001b[39m."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark copy_cuda!(d_A, $d_B) setup=(d_A = similar(d_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_iWSWoFQR8l",
    "outputId": "b7819aaf-1d42-416e-a0be-24eb728db0dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 242.23 µs, capturing 261 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 122.55 µs (50.59% of the trace)\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                   \u001b[0m│\u001b[1m Name                    \u001b[0m│\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────────┼─────────────────────────┤\n",
       "│   33.27% │\u001b[31m   80.59 µs \u001b[0m│    10 │   8.06 µs ± 10.45  (  2.86 ‥ 37.19) │\u001b[1m cuLaunchKernel          \u001b[0m│\n",
       "│    4.04% │    9.78 µs │     1 │                                     │ cuMemAllocFromPoolAsync │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────────┴─────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 27.89 µs (11.52% of the trace)\n",
       "┌──────────┬────────────┬───────┬────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                  \u001b[0m│\u001b[1m Name                                                                          \u001b[0m│\n",
       "├──────────┼────────────┼───────┼────────────────────────────────────┼───────────────────────────────────────────────────────────────────────────────┤\n",
       "│   11.52% │\u001b[31m   27.89 µs \u001b[0m│    10 │   2.79 µs ± 0.12   (  2.62 ‥ 2.86) │\u001b[1m copy_kernel_cuda_(CuDeviceArray<Float64, 1, 1>, CuDeviceArray<Float64, 1, 1>) \u001b[0m│\n",
       "└──────────┴────────────┴───────┴────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.@profile let\n",
    "  d_A = similar(d_B)\n",
    "  for _ in 1:10\n",
    "    copy_cuda!(d_A, d_B)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDtBttwaQlRq"
   },
   "source": [
    "So there seems to be a discrepancy between the measurement of `@benchmark` and `CUDA.@profile`, `@benchmark` seems to vastly over-estimate the performance of the GPU code. To remedy this we need to include a synchronization operation with benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcXwhR-nQklV",
    "outputId": "00ee47ab-b21f-4808-c9fb-ae205d79ae88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m14.428 μs\u001b[22m\u001b[39m … \u001b[35m82.189 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m16.251 μs              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m17.593 μs\u001b[22m\u001b[39m ± \u001b[32m 3.389 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▅\u001b[39m█\u001b[39m▄\u001b[39m▃\u001b[39m▁\u001b[34m▂\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▁\u001b[39m▄\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▇\u001b[39m▅\u001b[39m▃\u001b[39m▂\u001b[32m▂\u001b[39m\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▄\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▂\n",
       "  14.4 μs\u001b[90m         Histogram: frequency by time\u001b[39m        28.5 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m400 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m22\u001b[39m."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark CUDA.@sync(copy_cuda!(d_A, $d_B)) setup=(d_A = similar(d_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfM7FARLRQ7P"
   },
   "source": [
    "With KernelAbstractions we can now write code that is portable and can be used both for data that resides on the CPU as well as the GPU, therefore implementing the \"Compute follows Data\" paradigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "YFRjXDPgRhdp"
   },
   "outputs": [],
   "source": [
    "let\n",
    "  A = similar(B)\n",
    "  copy_ka!(A, B)\n",
    "  @assert A == B\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BAiptA8FRhHX"
   },
   "outputs": [],
   "source": [
    "let\n",
    "  d_A = similar(d_B)\n",
    "  copy_ka!(d_A, d_B)\n",
    "  @assert d_A == d_B\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1_l8pGvRvPm",
    "outputId": "da729235-93e9-4aad-b49d-f6d90fccfad5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m35.620 μs\u001b[22m\u001b[39m … \u001b[35m231.688 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m56.639 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m57.426 μs\u001b[22m\u001b[39m ± \u001b[32m  8.591 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[34m▇\u001b[39m\u001b[32m▆\u001b[39m\u001b[39m▇\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▄\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▃\n",
       "  35.6 μs\u001b[90m         Histogram: frequency by time\u001b[39m         87.9 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m11.16 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m160\u001b[39m."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark copy_ka!(A, $B) setup=(A = similar(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IyrrlbHRulN",
    "outputId": "2c750443-8c9f-40fb-f5c1-8dc0c6bbc8b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m17.263 μs\u001b[22m\u001b[39m … \u001b[35m111.165 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m19.838 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m21.397 μs\u001b[22m\u001b[39m ± \u001b[32m  3.962 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m▆\u001b[39m█\u001b[39m▆\u001b[39m▃\u001b[39m▂\u001b[39m▄\u001b[34m▂\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▁\u001b[39m▃\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m▅\u001b[39m▄\u001b[39m▂\u001b[39m▂\u001b[32m▂\u001b[39m\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▅\u001b[39m▇\u001b[39m▆\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▃\n",
       "  17.3 μs\u001b[90m         Histogram: frequency by time\u001b[39m         34.3 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m1.31 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m54\u001b[39m."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark CUDA.@sync(copy_ka!(d_A, $d_B)) setup=(d_A = similar(d_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5LYIpSySgxC",
    "outputId": "4336f30f-bd14-4131-b6da-08879190a33b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 244.86 µs, capturing 261 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 96.56 µs (39.44% of the trace)\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                   \u001b[0m│\u001b[1m Name                    \u001b[0m│\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────────┼─────────────────────────┤\n",
       "│   25.80% │\u001b[31m   63.18 µs \u001b[0m│    10 │   6.32 µs ± 8.95   (  2.86 ‥ 31.71) │\u001b[1m cuLaunchKernel          \u001b[0m│\n",
       "│    4.97% │   12.16 µs │     1 │                                     │ cuMemAllocFromPoolAsync │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────────┴─────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 28.61 µs (11.68% of the trace)\n",
       "┌──────────┬────────────┬───────┬───────────────────────────────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                 \u001b[0m│\u001b[1m Name                                                                                                                                                                                                                                                                                                \u001b[0m│\n",
       "├──────────┼────────────┼───────┼───────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│   11.68% │\u001b[31m   28.61 µs \u001b[0m│    10 │   2.86 µs ± 0.16   (  2.62 ‥ 3.1) │\u001b[1m gpu_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<1, Tuple<OneTo<Int64>>>, NDRange<1, DynamicSize, DynamicSize, CartesianIndices<1, Tuple<OneTo<Int64>>>, CartesianIndices<1, Tuple<OneTo<Int64>>>>>, CuDeviceArray<Float64, 1, 1>, CuDeviceArray<Float64, 1, 1>) \u001b[0m│\n",
       "└──────────┴────────────┴───────┴───────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.@profile let\n",
    "  d_A = similar(d_B)\n",
    "  for _ in 1:10\n",
    "    copy_ka!(d_A, d_B)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QDwG01WSwS4"
   },
   "source": [
    "We can see that KernelAbstractions is a bit slower than pure CUDA, and that is partially expected due to some convenience functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxXONwE_UYGF"
   },
   "source": [
    "## A more compilcated kernel -- transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdwzZOQ9VQWw",
    "outputId": "113e0401-d903-4a26-abc3-2966c99659c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const nreps = 3\n",
    "const N = 2048\n",
    "const T = Float32\n",
    "\n",
    "const TILE_DIM = 32\n",
    "const BLOCK_ROWS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O732YI3WWCnE"
   },
   "source": [
    "### Naive kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWDdbIl1UjYC",
    "outputId": "c5f150ab-e20f-4fd7-9b09-bf900ef14a7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simple_copy_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function simple_copy_kernel!(output, @Const(input))\n",
    "    I, J = @index(Global, NTuple)\n",
    "    @inbounds output[I, J] = input[I, J]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k3sMLN2lT7s2",
    "outputId": "f4478256-b35e-473a-cbb1-4ef80cceadf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simple_transpose_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function simple_transpose_kernel!(output, @Const(input))\n",
    "    I, J = @index(Global, NTuple)\n",
    "    @inbounds output[J, I] = input[I, J]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbG1_3QPWFhN"
   },
   "source": [
    "### Using localmemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEBb8iCUUg2Q",
    "outputId": "321302ec-d358-47c8-f8fa-56956073a03f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lmem_copy_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel inbounds = true function lmem_copy_kernel!(\n",
    "        output, @Const(input),\n",
    "        ::Val{BANK} = Val(1),\n",
    "    ) where {BANK}\n",
    "    I, J = @index(Global, NTuple)\n",
    "    i, j = @index(Local, NTuple)\n",
    "\n",
    "    N = @uniform @groupsize()[1]\n",
    "    M = @uniform @groupsize()[2]\n",
    "\n",
    "    # +1 to avoid bank conflicts on shared memory\n",
    "    tile = @localmem eltype(output) (N + BANK, M)\n",
    "\n",
    "    @inbounds tile[i, j] = input[I, J]\n",
    "\n",
    "    @synchronize\n",
    "\n",
    "    @inbounds output[I, J] = tile[i, j]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZHI9w-ggUE3y",
    "outputId": "075333c3-d4d3-4f0c-9fc0-90f5c9466a2a"
   },
   "outputs": [],
   "source": [
    "@kernel inbounds = false function lmem_transpose_kernel!(\n",
    "        output, @Const(input),\n",
    "        ::Val{BANK} = Val(1),\n",
    "    ) where {BANK}\n",
    "    gi, gj = @index(Group, NTuple)\n",
    "    i, j = @index(Local, NTuple)\n",
    "\n",
    "    N = @uniform @groupsize()[1]\n",
    "    M = @uniform @groupsize()[2]\n",
    "\n",
    "    # +1 to avoid bank conflicts on shared memory\n",
    "    tile = @localmem eltype(output) (N + BANK, M)\n",
    "\n",
    "    # Manually calculate global indexes\n",
    "    # Later on we need to pivot the group index\n",
    "    I = (gi - 1) * N + i\n",
    "    J = (gj - 1) * M + j\n",
    "\n",
    "    @inbounds tile[i, j] = input[I, J]\n",
    "\n",
    "    @synchronize\n",
    "\n",
    "    # Pivot the group index\n",
    "    I = (gj - 1) * M + i\n",
    "    J = (gi - 1) * N + j\n",
    "\n",
    "    @inbounds output[I, J] = tile[j, i]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peMDm9SvVtrv"
   },
   "source": [
    "### Local Memory + process multiple elements per lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "JNhPHFEqU3Si"
   },
   "outputs": [],
   "source": [
    "using KernelAbstractions.Extras: @unroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inJxG14QVrKe",
    "outputId": "35a2b35c-52f5-4fd9-961c-43d45745b262"
   },
   "outputs": [],
   "source": [
    "@kernel inbounds=false function coalesced_copy_kernel!(\n",
    "        output, @Const(input),\n",
    "        ::Val{BANK} = Val(1),\n",
    "    ) where {BANK}\n",
    "    gi, gj = @index(Group, NTuple)\n",
    "    i, j = @index(Local, NTuple)\n",
    "\n",
    "    TILE_DIM = @uniform @groupsize()[1]\n",
    "    BLOCK_ROWS = @uniform @groupsize()[2]\n",
    "\n",
    "    # +1 to avoid bank conflicts on shared memory\n",
    "    tile = @localmem eltype(output) (TILE_DIM + BANK, TILE_DIM)\n",
    "\n",
    "    # Can't use @index(Global), because we use a smaller ndrange\n",
    "    I = (gi - 1) * TILE_DIM + i\n",
    "    J = (gj - 1) * TILE_DIM + j\n",
    "\n",
    "    @unroll for k in 0:BLOCK_ROWS:(TILE_DIM - 1)\n",
    "        @inbounds tile[i, j + k] = input[I, J + k]\n",
    "    end\n",
    "\n",
    "    @synchronize\n",
    "\n",
    "    @unroll for k in 0:BLOCK_ROWS:(TILE_DIM - 1)\n",
    "        @inbounds output[I, J + k] = tile[i, j + k]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XkybpxxlUS-2",
    "outputId": "fbc8dbad-31c3-4025-b945-68a46836de3d"
   },
   "outputs": [],
   "source": [
    "@kernel inbounds = false function coalesced_transpose_kernel!(\n",
    "        output, @Const(input),\n",
    "        ::Val{BANK} = Val(1),\n",
    "    ) where {BANK}\n",
    "    gi, gj = @index(Group, NTuple)\n",
    "    i, j = @index(Local, NTuple)\n",
    "\n",
    "    TILE_DIM = @uniform @groupsize()[1]\n",
    "    BLOCK_ROWS = @uniform @groupsize()[2]\n",
    "\n",
    "    # +1 to avoid bank conflicts on shared memory\n",
    "    tile = @localmem eltype(output) (TILE_DIM + BANK, TILE_DIM)\n",
    "\n",
    "    # Can't use @index(Global), because we use a smaller ndrange\n",
    "    I = (gi - 1) * TILE_DIM + i\n",
    "    J = (gj - 1) * TILE_DIM + j\n",
    "\n",
    "    @unroll for k in 0:BLOCK_ROWS:(TILE_DIM - 1)\n",
    "        @inbounds tile[i, j + k] = input[I, J + k]\n",
    "    end\n",
    "\n",
    "    @synchronize\n",
    "\n",
    "    # Transpose block offsets\n",
    "    I = (gj - 1) * TILE_DIM + i\n",
    "    J = (gi - 1) * TILE_DIM + j\n",
    "\n",
    "    @unroll for k in 0:BLOCK_ROWS:(TILE_DIM - 1)\n",
    "        @inbounds output[I, J + k] = tile[j + k, i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rq2pCjP4V6wf"
   },
   "source": [
    "### Benchmark harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "AsJ95M-OVKPv"
   },
   "outputs": [],
   "source": [
    "using NVTX, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lLdmw2nV-WT",
    "outputId": "d67c9e94-52e9-4d52-ef37-6618ea382991"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDABackend(false, false)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend = CUDABackend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0A6CvDaVMnz",
    "outputId": "092aebc1-a8fc-4397-c308-25d2335f61d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 2.83 s, capturing 5071 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 75.82 ms (2.68% of the trace)\n",
       "┌──────────┬────────────┬───────┬───────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                     \u001b[0m│\u001b[1m Name                    \u001b[0m│\n",
       "├──────────┼────────────┼───────┼───────────────────────────────────────┼─────────────────────────┤\n",
       "│    2.05% │\u001b[31m   57.88 ms \u001b[0m│     7 │   8.27 ms ± 14.28  (  0.01 ‥ 32.83)   │\u001b[1m cudaLaunchKernel        \u001b[0m│\n",
       "│    0.05% │\u001b[31m    1.54 ms \u001b[0m│     1 │                                       │\u001b[1m cudaMalloc              \u001b[0m│\n",
       "│    0.03% │\u001b[33m  952.24 µs \u001b[0m│     6 │ 158.71 µs ± 47.11  (130.89 ‥ 252.49)  │\u001b[1m cuModuleLoadDataEx      \u001b[0m│\n",
       "│    0.03% │\u001b[33m  729.32 µs \u001b[0m│    12 │  60.78 µs ± 76.82  (  2.15 ‥ 166.42)  │\u001b[1m cuMemAllocFromPoolAsync \u001b[0m│\n",
       "│    0.01% │\u001b[33m  251.77 µs \u001b[0m│     1 │                                       │\u001b[1m cudaDeviceSynchronize   \u001b[0m│\n",
       "│    0.01% │\u001b[33m  236.27 µs \u001b[0m│    24 │   9.84 µs ± 9.42   (   3.1 ‥ 29.8)    │\u001b[1m cuLaunchKernel          \u001b[0m│\n",
       "│    0.01% │   190.5 µs │     1 │                                       │ cudaFree                │\n",
       "│    0.01% │  184.77 µs │     6 │   30.8 µs ± 5.34   ( 23.13 ‥ 36.95)   │ cuModuleGetFunction     │\n",
       "│    0.00% │   77.72 µs │     6 │  12.95 µs ± 12.66  (  2.86 ‥ 34.09)   │ cuStreamSynchronize     │\n",
       "│    0.00% │   72.96 µs │     6 │  12.16 µs ± 2.77   (  9.54 ‥ 16.69)   │ cuCtxSynchronize        │\n",
       "│    0.00% │   38.39 µs │     4 │    9.6 µs ± 9.67   (  4.05 ‥ 24.08)   │ cuDeviceGetName         │\n",
       "│    0.00% │   19.07 µs │     4 │   4.77 µs ± 5.28   (  1.43 ‥ 12.64)   │ cuMemFreeAsync          │\n",
       "│    0.00% │   16.21 µs │     4 │   4.05 µs ± 4.77   (  1.43 ‥ 11.21)   │ cuCtxSetCurrent         │\n",
       "│    0.00% │   15.26 µs │    86 │ 177.43 ns ± 874.81 (   0.0 ‥ 8106.23) │ cuDeviceGetCount        │\n",
       "│    0.00% │    6.44 µs │    14 │ 459.81 ns ± 343.14 (   0.0 ‥ 1192.09) │ cudaGetLastError        │\n",
       "│    0.00% │    5.96 µs │     1 │                                       │ cudaGetDevice           │\n",
       "│    0.00% │    4.77 µs │     1 │                                       │ cuInit                  │\n",
       "│    0.00% │    1.91 µs │     4 │ 476.84 ns ± 275.3  (238.42 ‥ 715.26)  │ cuCtxGetDevice          │\n",
       "│    0.00% │  953.67 ns │     4 │ 238.42 ns ± 194.67 (   0.0 ‥ 476.84)  │ cuDeviceGet             │\n",
       "│    0.00% │  953.67 ns │     4 │ 238.42 ns ± 0.0    (238.42 ‥ 238.42)  │ cuDeviceTotalMem        │\n",
       "│    0.00% │  715.26 ns │     3 │ 238.42 ns ± 0.0    (238.42 ‥ 238.42)  │ cudaDeviceGetAttribute  │\n",
       "│    0.00% │  476.84 ns │     4 │ 119.21 ns ± 137.65 (   0.0 ‥ 238.42)  │ cuDeviceGetUuid         │\n",
       "│    0.00% │  238.42 ns │     1 │                                       │ cuModuleGetLoadingMode  │\n",
       "│    0.00% │     0.0 ns │     1 │                                       │ cuDriverGetVersion      │\n",
       "└──────────┴────────────┴───────┴───────────────────────────────────────┴─────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 2.94 ms (0.10% of the trace)\n",
       "┌──────────┬────────────┬───────┬──────────────────────────────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                    \u001b[0m│\u001b[1m Name                                                                                                                                                                                                                                                                                         \u001b[0m│\n",
       "├──────────┼────────────┼───────┼──────────────────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│    0.03% │\u001b[31m  757.69 µs \u001b[0m│     4 │ 189.42 µs ± 0.57   (188.83 ‥ 190.02) │\u001b[1m gpu_simple_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_1__1024_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32)      \u001b[0m│\n",
       "│    0.02% │\u001b[33m  555.04 µs \u001b[0m│     4 │ 138.76 µs ± 5.27   (135.66 ‥ 146.63) │\u001b[1m gpu_simple_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_1024__1_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32) \u001b[0m│\n",
       "│    0.02% │  544.31 µs │     4 │ 136.08 µs ± 0.63   (135.18 ‥ 136.61) │ gpu_simple_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32)  │\n",
       "│    0.01% │  288.49 µs │     4 │  72.12 µs ± 0.79   ( 71.05 ‥ 72.72)  │ gpu_simple_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_1__1024_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32) │\n",
       "│    0.01% │  245.09 µs │     1 │                                      │ void generate_seed_pseudo<rng_config<curandStateXORWOW, (curandOrdering)101>>(unsigned long long, unsigned long long, unsigned long long, curandOrdering, curandStateXORWOW*, unsigned int*)                                                                                                 │\n",
       "│    0.01% │  225.78 µs │     6 │  37.63 µs ± 0.18   ( 37.43 ‥ 37.91)  │ void gen_sequenced<curandStateXORWOW, float, int, &float curand_uniform_noargs<curandStateXORWOW>(curandStateXORWOW*, int), rng_config<curandStateXORWOW, (curandOrdering)101>>(curandStateXORWOW*, float*, unsigned long, unsigned long, int)                                               │\n",
       "│    0.01% │  169.52 µs │     4 │  42.38 µs ± 2.35   ( 38.86 ‥ 43.63)  │ gpu_simple_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32)       │\n",
       "│    0.01% │  159.03 µs │     4 │  39.76 µs ± 2.35   ( 36.24 ‥ 41.01)  │ gpu_simple_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_1024__1_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32)      │\n",
       "└──────────┴────────────┴───────┴──────────────────────────────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "\n",
       "NVTX ranges:\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Name                            \u001b[0m│\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────┤\n",
       "│   50.73% │\u001b[31m     1.43 s \u001b[0m│     1 │\u001b[1m Main.Simple copy (32, 32)       \u001b[0m│\n",
       "│   12.49% │\u001b[33m   353.0 ms \u001b[0m│     1 │\u001b[1m Main.Simple copy (1024, 1)      \u001b[0m│\n",
       "│   11.03% │  311.64 ms │     1 │ Main.Simple transpose (32, 32)  │\n",
       "│    9.98% │  282.19 ms │     1 │ Main.Simple copy (1, 1024)      │\n",
       "│    8.30% │  234.63 ms │     1 │ Main.Simple transpose (1, 1024) │\n",
       "│    6.84% │  193.41 ms │     1 │ Main.Simple transpose (1024, 1) │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────┘\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.@profile for block_dims in ((TILE_DIM, TILE_DIM), (TILE_DIM * TILE_DIM, 1), (1, TILE_DIM * TILE_DIM))\n",
    "    for (name, kernel) in (\n",
    "            (\"copy\", simple_copy_kernel!(backend, block_dims)),\n",
    "            (\"transpose\", simple_transpose_kernel!(backend, block_dims)),\n",
    "        )\n",
    "        NVTX.@range \"Simple $name $block_dims\" let\n",
    "            input = rand!(allocate(backend, T, N, N))\n",
    "            output = similar(input)\n",
    "\n",
    "            # compile kernel\n",
    "            kernel(output, input, ndrange = size(output))\n",
    "            for rep in 1:nreps\n",
    "                kernel(output, input, ndrange = size(output))\n",
    "            end\n",
    "            KernelAbstractions.synchronize(backend)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwL2dy7XVd4Z",
    "outputId": "e5b82069-5491-43bd-b6d4-76bcc7c0db82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 997.04 ms, capturing 1846 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 1.43 ms (0.14% of the trace)\n",
       "┌──────────┬────────────┬───────┬───────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                     \u001b[0m│\u001b[1m Name                    \u001b[0m│\n",
       "├──────────┼────────────┼───────┼───────────────────────────────────────┼─────────────────────────┤\n",
       "│    0.06% │\u001b[31m  602.25 µs \u001b[0m│     4 │ 150.56 µs ± 9.64   (138.28 ‥ 160.46)  │\u001b[1m cuModuleLoadDataEx      \u001b[0m│\n",
       "│    0.02% │\u001b[33m  179.29 µs \u001b[0m│    16 │  11.21 µs ± 12.32  (   3.1 ‥ 38.86)   │\u001b[1m cuLaunchKernel          \u001b[0m│\n",
       "│    0.01% │  132.08 µs │     4 │  33.02 µs ± 7.9    ( 24.32 ‥ 42.2)    │ cuModuleGetFunction     │\n",
       "│    0.01% │   67.71 µs │     8 │   8.46 µs ± 4.11   (  2.86 ‥ 15.97)   │ cuMemAllocFromPoolAsync │\n",
       "│    0.01% │   53.41 µs │     4 │  13.35 µs ± 7.51   (  7.39 ‥ 24.08)   │ cudaLaunchKernel        │\n",
       "│    0.00% │   41.48 µs │     4 │  10.37 µs ± 0.74   (   9.3 ‥ 10.97)   │ cuCtxSynchronize        │\n",
       "│    0.00% │   16.21 µs │     4 │   4.05 µs ± 2.08   (  2.86 ‥ 7.15)    │ cuStreamSynchronize     │\n",
       "│    0.00% │    4.77 µs │     8 │ 596.05 ns ± 422.67 (   0.0 ‥ 1192.09) │ cudaGetLastError        │\n",
       "└──────────┴────────────┴───────┴───────────────────────────────────────┴─────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 1.0 ms (0.10% of the trace)\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                   \u001b[0m│\u001b[1m Name                                                                                                                                                                                                                                                                                              \u001b[0m│\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│    0.03% │\u001b[31m  303.98 µs \u001b[0m│     4 │   76.0 µs ± 3.46   ( 70.81 ‥ 77.96) │\u001b[1m gpu_lmem_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<0>) \u001b[0m│\n",
       "│    0.02% │\u001b[33m  183.58 µs \u001b[0m│     4 │   45.9 µs ± 2.35   ( 42.44 ‥ 47.68) │\u001b[1m gpu_lmem_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<1>) \u001b[0m│\n",
       "│    0.02% │  182.63 µs │     4 │  45.66 µs ± 2.94   ( 41.25 ‥ 47.21) │ gpu_lmem_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<0>)      │\n",
       "│    0.02% │  181.91 µs │     4 │  45.48 µs ± 2.82   ( 41.25 ‥ 46.97) │ gpu_lmem_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<1>)      │\n",
       "│    0.02% │  150.44 µs │     4 │  37.61 µs ± 0.12   ( 37.43 ‥ 37.67) │ void gen_sequenced<curandStateXORWOW, float, int, &float curand_uniform_noargs<curandStateXORWOW>(curandStateXORWOW*, int), rng_config<curandStateXORWOW, (curandOrdering)101>>(curandStateXORWOW*, float*, unsigned long, unsigned long, int)                                                    │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "\n",
       "NVTX ranges:\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Name                                        \u001b[0m│\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────────────────┤\n",
       "│   35.05% │\u001b[31m  349.49 ms \u001b[0m│     1 │\u001b[1m Main.Localmem copy (32, 32) bank=true       \u001b[0m│\n",
       "│   27.64% │  275.62 ms │     1 │ Main.Localmem transpose (32, 32) bank=true  │\n",
       "│   19.14% │  190.87 ms │     1 │ Main.Localmem copy (32, 32) bank=false      │\n",
       "│   16.49% │  164.39 ms │     1 │ Main.Localmem transpose (32, 32) bank=false │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────────────────┘\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark localmem\n",
    "CUDA.@profile for (name, kernel) in (\n",
    "        (\"copy\", lmem_copy_kernel!(backend, (TILE_DIM, TILE_DIM))),\n",
    "        (\"transpose\", lmem_transpose_kernel!(backend, (TILE_DIM, TILE_DIM))),\n",
    "    )\n",
    "    for bank in (true, false)\n",
    "        NVTX.@range \"Localmem $name ($TILE_DIM, $TILE_DIM) bank=$bank\" let\n",
    "            input = rand!(allocate(backend, T, N, N))\n",
    "            output = similar(input)\n",
    "\n",
    "            # compile kernel\n",
    "            kernel(output, input, Val(Int(bank)), ndrange = size(output))\n",
    "            for rep in 1:nreps\n",
    "                kernel(output, input, Val(Int(bank)), ndrange = size(output))\n",
    "            end\n",
    "            KernelAbstractions.synchronize(backend)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXxdCZBVVfj1",
    "outputId": "001f2805-91ab-4c25-eadc-a87ed3cf07dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 1.09 s, capturing 1210 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 1.31 ms (0.12% of the trace)\n",
       "┌──────────┬────────────┬───────┬───────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                     \u001b[0m│\u001b[1m Name                    \u001b[0m│\n",
       "├──────────┼────────────┼───────┼───────────────────────────────────────┼─────────────────────────┤\n",
       "│    0.05% │\u001b[31m  575.78 µs \u001b[0m│     4 │ 143.95 µs ± 15.69  (130.18 ‥ 166.42)  │\u001b[1m cuModuleLoadDataEx      \u001b[0m│\n",
       "│    0.02% │\u001b[33m  172.38 µs \u001b[0m│    16 │  10.77 µs ± 10.2   (   3.1 ‥ 28.85)   │\u001b[1m cuLaunchKernel          \u001b[0m│\n",
       "│    0.01% │\u001b[33m  118.73 µs \u001b[0m│     4 │  29.68 µs ± 3.08   ( 25.27 ‥ 32.42)   │\u001b[1m cuModuleGetFunction     \u001b[0m│\n",
       "│    0.01% │   82.02 µs │     4 │   20.5 µs ± 18.11  (  8.34 ‥ 47.45)   │ cudaLaunchKernel        │\n",
       "│    0.01% │   57.46 µs │     8 │   7.18 µs ± 4.66   (  2.86 ‥ 14.31)   │ cuMemAllocFromPoolAsync │\n",
       "│    0.00% │   48.88 µs │     4 │  12.22 µs ± 5.06   (   9.3 ‥ 19.79)   │ cuCtxSynchronize        │\n",
       "│    0.00% │   41.72 µs │     4 │  10.43 µs ± 14.07  (  2.38 ‥ 31.47)   │ cuMemFreeAsync          │\n",
       "│    0.00% │   10.97 µs │     4 │   2.74 µs ± 0.24   (  2.38 ‥ 2.86)    │ cuStreamSynchronize     │\n",
       "│    0.00% │    5.01 µs │     8 │ 625.85 ns ± 708.84 (   0.0 ‥ 2145.77) │ cudaGetLastError        │\n",
       "│    0.00% │    1.43 µs │     1 │                                       │ cuCtxSetCurrent         │\n",
       "│    0.00% │  238.42 ns │     1 │                                       │ cuCtxGetDevice          │\n",
       "│    0.00% │  238.42 ns │     1 │                                       │ cuDeviceGetCount        │\n",
       "└──────────┴────────────┴───────┴───────────────────────────────────────┴─────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 597.48 µs (0.06% of the trace)\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                   \u001b[0m│\u001b[1m Name                                                                                                                                                                                                                                                                                                  \u001b[0m│\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│    0.02% │\u001b[31m  195.03 µs \u001b[0m│     4 │  48.76 µs ± 0.9    ( 47.45 ‥ 49.35) │\u001b[1m gpu_coalesced_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__8_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<0>) \u001b[0m│\n",
       "│    0.01% │\u001b[33m  150.44 µs \u001b[0m│     4 │  37.61 µs ± 0.12   ( 37.43 ‥ 37.67) │\u001b[1m void gen_sequenced<curandStateXORWOW, float, int, &float curand_uniform_noargs<curandStateXORWOW>(curandStateXORWOW*, int), rng_config<curandStateXORWOW, (curandOrdering)101>>(curandStateXORWOW*, float*, unsigned long, unsigned long, int)                                                        \u001b[0m│\n",
       "│    0.01% │   86.78 µs │     4 │   21.7 µs ± 2.19   ( 19.55 ‥ 24.56) │ gpu_coalesced_transpose_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__8_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<1>) │\n",
       "│    0.01% │   83.21 µs │     4 │   20.8 µs ± 3.8    ( 16.93 ‥ 25.03) │ gpu_coalesced_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__8_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<0>)      │\n",
       "│    0.01% │   82.02 µs │     4 │   20.5 µs ± 3.4    ( 16.69 ‥ 24.32) │ gpu_coalesced_copy_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__8_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float32, 2, 1>, Float32, Val<1>)      │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "\n",
       "NVTX ranges:\n",
       "┌──────────┬────────────┬───────┬────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Name                                                           \u001b[0m│\n",
       "├──────────┼────────────┼───────┼────────────────────────────────────────────────────────────────┤\n",
       "│   36.80% │\u001b[31m  399.39 ms \u001b[0m│     1 │\u001b[1m Main.Localmem + multiple elements copy (32, 8) bank=true       \u001b[0m│\n",
       "│   28.29% │  306.96 ms │     1 │ Main.Localmem + multiple elements transpose (32, 8) bank=true  │\n",
       "│   17.13% │  185.89 ms │     1 │ Main.Localmem + multiple elements copy (32, 8) bank=false      │\n",
       "│   16.09% │  174.63 ms │     1 │ Main.Localmem + multiple elements transpose (32, 8) bank=false │\n",
       "└──────────┴────────────┴───────┴────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark localmem + multiple elements per lane\n",
    "CUDA.@profile for (name, kernel) in (\n",
    "        (\"copy\", coalesced_copy_kernel!(backend, (TILE_DIM, BLOCK_ROWS))),\n",
    "        (\"transpose\", coalesced_transpose_kernel!(backend, (TILE_DIM, BLOCK_ROWS))),\n",
    "    )\n",
    "    for bank in (true, false)\n",
    "        NVTX.@range \"Localmem + multiple elements $name ($TILE_DIM, $BLOCK_ROWS) bank=$bank\" let\n",
    "            input = rand!(allocate(backend, T, N, N))\n",
    "            output = similar(input)\n",
    "\n",
    "            # We want a number of blocks equivalent to (TILE_DIM, TILE_DIM)\n",
    "            # but our blocks are (TILE_DIM, BLOCK_ROWS) so we need to remove\n",
    "            # a factor from the size of the array otherwise we get to many blocks\n",
    "            block_factor = div(TILE_DIM, BLOCK_ROWS)\n",
    "            ndrange = (N, div(N, block_factor))\n",
    "\n",
    "            # compile kernel\n",
    "            kernel(output, input, Val(Int(bank)), ndrange = ndrange)\n",
    "            for rep in 1:nreps\n",
    "                kernel(output, input, Val(Int(bank)), ndrange = ndrange)\n",
    "            end\n",
    "            KernelAbstractions.synchronize(backend)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNekriU2bSRB"
   },
   "source": [
    "## Atomic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yV55CsqMW1e0",
    "outputId": "df8dc127-bd63-4cb2-87f2-857b005387a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "racy_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function racy_kernel!(out, arr)\n",
    "\ti, j = @index(Global, NTuple)\n",
    "\tfor k in 1:size(out, 1)\n",
    "\t\tout[k, i] += arr[i, j]\n",
    "\tend\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Y9j2kFZ1ceBj"
   },
   "outputs": [],
   "source": [
    "using ImageShow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "1wLZB_bHbYiJ",
    "outputId": "40f3f1a8-6cb8-4b57-d29c-af7332a6a222"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAALFJREFUaAW9wTEKwCAAwMAIebg/b6dOikOR3ElAAhKQgAQkIAEJSEACEpCABCQgAQlIQAKymOxM/pOABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJyGJymwQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAG54GFn8JGABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJyAWDMwlIQAISkIAEJCABCby1LAQS5D4/RAAAAABJRU5ErkJggg==",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAALFJREFUaAW9wTEKwCAAwMAIebg/b6dOikOR3ElAAhKQgAQkIAEJSEACEpCABCQgAQlIQAKymOxM/pOABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJyGJymwQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAG54GFn8JGABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJyAWDMwlIQAISkIAEJCABCby1LAQS5D4/RAAAAABJRU5ErkJg\">"
      ],
      "text/plain": [
       "50×50 Array{Gray{Float32},2} with eltype ColorTypes.Gray{Float32}:\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " ⋮                                       ⋱  \n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = zeros(Float32, (50, 50));\n",
    "img[10:20, 10:20] .= 1;\n",
    "img[35:45, 35:45] .= 2;\n",
    "simshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "Y8t0Q2QpbdkM",
    "outputId": "15354de3-18d7-4e7d-d04a-266968b297b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAkVJREFUaAW9wdGtIkkMAMD6cDRNPL4gz/HgeE4jNAK2h4G3j+uqsEBYIBwaGsNd+0QqqTwLC4TJsBl+IpVESaRN2YUFwguN4TOJtElHwgLhheF7wgJh0h4N7Z10pOzCAmEy7BqNgfZaORcWCJO2Gdqu/U5YIEyGm+FReyeVtCnPwgJh0h4N76WSNuVIWCBMhp8qFNKm/CksEL6obFJ5FhYIk/YbaRYWCJNh136uzMIC4cRA+72wQPiCdFNIlGdhgXCoMbTPlLsyCwuEQ8M3hQXCAmGBMLnYtbQpqfy9sECYlLtyU34jLBAmw679nbQpu7BAODHctc+VZ2GBMGnfFhYIk2HXviMsEP4HqaSyCwuEA42hfSo9K5S7sEA4MGyGNmza0F5Ld2UWFggnhk0bzpVzYYHw1vCZko6FBcKJ9plCohwLC4QTA+29tEm78iwsEA60gYurzbBpr5VzYYEwuWgXlIFh095JlJtUUtmFBcKkDFekMtCGoZ1JJe1KKndhgTBJu6ENnyiUu/IoLBBODW34VCqk8iwsECZX7VF7J92UTflTWCBMLi5uru7aa+XRv/6Ryl1YIEyudu0ziZLK5h+UR2GBMLkoadN+orwSFggHhqvNcNfOlEQ5FhYIBy5m7VxJu1QehQXCB8onyq48CwuEFwrDRWGgnUmbciwsECYlXQ20m3Yu3ZRjYYFw4OpmaEN7pzxLm7ILC4QD7a69V+4S5VlYIEwSVxdXNxflc2UWFgiTq00Z2sDVQHstlUTZpJIou7DAf5MzkUd/b5rIAAAAAElFTkSuQmCC",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAkVJREFUaAW9wdGtIkkMAMD6cDRNPL4gz/HgeE4jNAK2h4G3j+uqsEBYIBwaGsNd+0QqqTwLC4TJsBl+IpVESaRN2YUFwguN4TOJtElHwgLhheF7wgJh0h4N7Z10pOzCAmEy7BqNgfZaORcWCJO2Gdqu/U5YIEyGm+FReyeVtCnPwgJh0h4N76WSNuVIWCBMhp8qFNKm/CksEL6obFJ5FhYIk/YbaRYWCJNh136uzMIC4cRA+72wQPiCdFNIlGdhgXCoMbTPlLsyCwuEQ8M3hQXCAmGBMLnYtbQpqfy9sECYlLtyU34jLBAmw679nbQpu7BAODHctc+VZ2GBMGnfFhYIk2HXviMsEP4HqaSyCwuEA42hfSo9K5S7sEA4MGyGNmza0F5Ld2UWFggnhk0bzpVzYYHw1vCZko6FBcKJ9plCohwLC4QTA+29tEm78iwsEA60gYurzbBpr5VzYYEwuWgXlIFh095JlJtUUtmFBcKkDFekMtCGoZ1JJe1KKndhgTBJu6ENnyiUu/IoLBBODW34VCqk8iwsECZX7VF7J92UTflTWCBMLi5uru7aa+XRv/6Ryl1YIEyudu0ziZLK5h+UR2GBMLkoadN+orwSFggHhqvNcNfOlEQ5FhYIBy5m7VxJu1QehQXCB8onyq48CwuEFwrDRWGgnUmbciwsECYlXQ20m3Yu3ZRjYYFw4OpmaEN7pzxLm7ILC4QD7a69V+4S5VlYIEwSVxdXNxflc2UWFgiTq00Z2sDVQHstlUTZpJIou7DAf5MzkUd/b5rIAAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "50×50 Array{Gray{Float32},2} with eltype ColorTypes.Gray{Float32}:\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " ⋮                                       ⋱  \n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = KernelAbstractions.zeros(backend, Float32, size(img));\n",
    "racy_kernel!(backend)(out, adapt(backend, img), ndrange=size(img))\n",
    "simshow(Array(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "V02D9krWbvAN"
   },
   "outputs": [],
   "source": [
    "using Atomix: @atomic, @atomicswap, @atomicreplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jD0eol-2cx41",
    "outputId": "d77fe6bc-4778-4c47-82a5-51f57232edb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nonracy_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function nonracy_kernel!(out, arr)\n",
    "\ti, j = @index(Global, NTuple)\n",
    "\tfor k in 1:size(out, 1)\n",
    "\t\t@atomic out[k, i] += arr[i, j]\n",
    "\tend\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "Sa-Gzr7tc61f",
    "outputId": "4adde915-9d32-44d2-829a-dd14162e1540"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAKpJREFUaAW9wTESABAAwLC668P9nMmEtYlcJi+Tv8XL4JCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCSwAdRJA5GDmgLcAAAAAElFTkSuQmCC",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAKpJREFUaAW9wTESABAAwLC668P9nMmEtYlcJi+Tv8XL4JCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCQgAQlIQAISkIAEJCABCUhAAhKQgAQkIAEJSEACEpCABCSwAdRJA5GDmgLcAAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "50×50 Array{Gray{Float32},2} with eltype ColorTypes.Gray{Float32}:\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " ⋮                                       ⋱  \n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = KernelAbstractions.zeros(backend, Float32, size(img));\n",
    "nonracy_kernel!(backend)(out, adapt(backend, img), ndrange=size(img))\n",
    "simshow(Array(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoCwrdAKd1Ut"
   },
   "source": [
    "## Matrix multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJ7ErQTfd4ZO",
    "outputId": "263e9c3b-580a-4edc-a661-cce2c4ca3fab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "naive_matmul_kernel! (generic function with 4 methods)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function naive_matmul_kernel!(output, a, b)\n",
    "    i, j = @index(Global, NTuple)\n",
    "\n",
    "    # creating a temporary sum variable for matrix multiplication\n",
    "    tmp_sum = zero(eltype(output))\n",
    "    for k in 1:size(a)[2]\n",
    "        tmp_sum += a[i, k] * b[k, j]\n",
    "    end\n",
    "\n",
    "    output[i, j] = tmp_sum\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "-miQrox1ebjt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "naive_matmul! (generic function with 1 method)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a wrapper kernel for launching with error checks\n",
    "function naive_matmul!(output, a, b)\n",
    "    if size(a)[2] != size(b)[1]\n",
    "        println(\"Matrix size mismatch!\")\n",
    "        return nothing\n",
    "    end\n",
    "    backend = KernelAbstractions.get_backend(a)\n",
    "    kernel! = naive_matmul_kernel!(backend)\n",
    "    kernel!(output, a, b, ndrange = size(output))\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "fc4MplI9d89w"
   },
   "outputs": [],
   "source": [
    "let\n",
    "  a = rand!(allocate(backend, Float32, 256, 123))\n",
    "  b = rand!(allocate(backend, Float32, 123, 45))\n",
    "  output = KernelAbstractions.zeros(backend, Float32, 256, 45)\n",
    "\n",
    "  naive_matmul!(output, a, b)\n",
    "\n",
    "  @assert isapprox(output, a * b)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "mN1LbGM7eGZL"
   },
   "outputs": [],
   "source": [
    "@kernel inbounds = false function coalesced_matmul_kernel!(\n",
    "        output, @Const(A), @Const(B),\n",
    "        ::Val{BANK} = Val(1),\n",
    "    ) where {BANK}\n",
    "    gi, gj = @index(Group, NTuple)\n",
    "    i, j = @index(Local, NTuple)\n",
    "\n",
    "    TILE_DIM = @uniform @groupsize()[1]\n",
    "\n",
    "    # +1 to avoid bank conflicts on shared memory\n",
    "    tile1 = @localmem eltype(output) (TILE_DIM + BANK, TILE_DIM)\n",
    "    tile2 = @localmem eltype(output) (TILE_DIM + BANK, TILE_DIM)\n",
    "\n",
    "    # private variable for tile output\n",
    "    outval = @private eltype(output) 1\n",
    "    @inbounds outval[1] = -zero(eltype(output))\n",
    "\n",
    "    @uniform N = size(output, 1)\n",
    "    @uniform M = size(output, 2)\n",
    "    @uniform R = size(A, 2)\n",
    "    # number of tiles depends on inner dimension\n",
    "    @uniform NUM_TILES = div(R + TILE_DIM - 1, TILE_DIM)\n",
    "\n",
    "    # loop over all tiles needed for this calculation\n",
    "    for t in 0:(NUM_TILES - 1)\n",
    "        # Can't use @index(Global), because we use a smaller ndrange\n",
    "        I = (gi - 1) * TILE_DIM + i\n",
    "        J = (gj - 1) * TILE_DIM + j\n",
    "\n",
    "        # load inputs into tiles, with bounds checking for non-square matrices\n",
    "        if I <= N && t * TILE_DIM + j <= R\n",
    "            @inbounds tile1[i, j] = A[I, t * TILE_DIM + j]\n",
    "        else\n",
    "            @inbounds tile1[i, j] = 0.0\n",
    "        end\n",
    "        if t * TILE_DIM + i <= R && J <= M\n",
    "            @inbounds tile2[i, j] = B[t * TILE_DIM + i, J]\n",
    "        else\n",
    "            @inbounds tile2[i, j] = 0.0\n",
    "        end\n",
    "\n",
    "        # wait for all tiles to be loaded\n",
    "        @synchronize\n",
    "\n",
    "        # get global values again\n",
    "        I = (gi - 1) * TILE_DIM + i\n",
    "        J = (gj - 1) * TILE_DIM + j\n",
    "\n",
    "        # calculate value of spot in output, use temporary value to allow for vectorization\n",
    "        out = zero(eltype(output))\n",
    "        @simd for k in 1:TILE_DIM\n",
    "            @inbounds out += tile1[i, k] * tile2[k, j]\n",
    "        end\n",
    "        outval[1] += out\n",
    "\n",
    "        @synchronize\n",
    "    end\n",
    "\n",
    "    # get global indices again\n",
    "    I = (gi - 1) * TILE_DIM + i\n",
    "    J = (gj - 1) * TILE_DIM + j\n",
    "\n",
    "    # save if inbounds\n",
    "    if I <= N && J <= M\n",
    "        @inbounds output[I, J] = outval[1]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dE4LNL5Zecj3",
    "outputId": "89ad6250-24b3-4d13-fde9-95731853b1de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coalesced_matmul! (generic function with 1 method)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a wrapper kernel for launching with error checks\n",
    "function coalesced_matmul!(output, a, b)\n",
    "    if size(a)[2] != size(b)[1]\n",
    "        println(\"Matrix size mismatch!\")\n",
    "        return nothing\n",
    "    end\n",
    "    backend = KernelAbstractions.get_backend(a)\n",
    "    kernel! = coalesced_matmul_kernel!(backend, (TILE_DIM, TILE_DIM))\n",
    "    kernel!(output, a, b, ndrange = size(output))\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "jM9J-KMnetKN"
   },
   "outputs": [],
   "source": [
    "let\n",
    "  a = rand!(allocate(backend, Float32, 32, 123))\n",
    "  b = rand!(allocate(backend, Float32, 123, 32))\n",
    "  output = KernelAbstractions.zeros(backend, Float32, 32, 32)\n",
    "\n",
    "  coalesced_matmul!(output, a, b)\n",
    "  @assert isapprox(output, a * b)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "i3ZPZNcmfv3b"
   },
   "outputs": [],
   "source": [
    "import LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw9Uuzn0hM0I"
   },
   "source": [
    "### Exercise\n",
    "- Vary N, R, M\n",
    "- Vary T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOwz86oLfYjs",
    "outputId": "fa4beb7d-9c82-4411-8fe9-5e12e37f6e8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 13.09 ms, capturing 6395 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 4.17 ms (31.90% of the trace)\n",
       "┌──────────┬────────────┬───────┬───────────────────────────────────────┬──────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                     \u001b[0m│\u001b[1m Name                                                 \u001b[0m│\n",
       "├──────────┼────────────┼───────┼───────────────────────────────────────┼──────────────────────────────────────────────────────┤\n",
       "│   67.42% │\u001b[31m    8.82 ms \u001b[0m│     9 │ 980.24 µs ± 902.35 (  1.19 ‥ 2095.46) │\u001b[1m cuStreamSynchronize                                  \u001b[0m│\n",
       "│    0.67% │\u001b[33m   87.26 µs \u001b[0m│     9 │    9.7 µs ± 6.11   (  4.53 ‥ 25.03)   │\u001b[1m cuLaunchKernel                                       \u001b[0m│\n",
       "│    0.38% │\u001b[33m   49.35 µs \u001b[0m│    48 │   1.03 µs ± 1.5    (  0.24 ‥ 8.58)    │\u001b[1m cuKernelGetFunction                                  \u001b[0m│\n",
       "│    0.26% │   34.57 µs │     6 │   5.76 µs ± 3.97   (  1.91 ‥ 10.97)   │ cuMemAllocFromPoolAsync                              │\n",
       "│    0.23% │   30.04 µs │     6 │   5.01 µs ± 2.26   (  2.86 ‥ 7.63)    │ cuMemcpyHtoDAsync                                    │\n",
       "│    0.03% │    3.81 µs │     3 │   1.27 µs ± 0.77   (  0.72 ‥ 2.15)    │ cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags │\n",
       "│    0.02% │    2.62 µs │     3 │  874.2 ns ± 496.31 (476.84 ‥ 1430.51) │ cudaDeviceGetAttribute                               │\n",
       "│    0.01% │    1.43 µs │     3 │ 476.84 ns ± 238.42 (238.42 ‥ 715.26)  │ cudaGetDevice                                        │\n",
       "│    0.01% │    1.43 µs │     3 │ 476.84 ns ± 238.42 (238.42 ‥ 715.26)  │ cuFuncGetAttribute                                   │\n",
       "└──────────┴────────────┴───────┴───────────────────────────────────────┴──────────────────────────────────────────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 12.2 ms (93.21% of the trace)\n",
       "┌──────────┬────────────┬───────┬──────────────────────────────────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                    \u001b[0m│\u001b[1m Name                                                                                                                                                                                                                                                                                                                                                                                \u001b[0m│\n",
       "├──────────┼────────────┼───────┼──────────────────────────────────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│   58.35% │\u001b[31m    7.64 ms \u001b[0m│     3 │   2.55 ms ± 0.04   (  2.52 ‥ 2.59)   │\u001b[1m gpu_naive_matmul_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, DynamicSize, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>>>, CuDeviceArray<Float64, 2, 1>, CuDeviceArray<Float64, 2, 1>, CuDeviceArray<Float64, 2, 1>) \u001b[0m│\n",
       "│   30.54% │     4.0 ms │     3 │   1.33 ms ± 0.0    (  1.33 ‥ 1.33)   │ gpu_coalesced_matmul_kernel_(CompilerMetadata<DynamicSize, DynamicCheck, void, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, NDRange<2, DynamicSize, StaticSize<_32__32_>, CartesianIndices<2, Tuple<OneTo<Int64>, OneTo<Int64>>>, void>>, CuDeviceArray<Float64, 2, 1>, Float64, Float64)                                                                                │\n",
       "│    4.25% │  556.23 µs │     3 │ 185.41 µs ± 0.36   (185.01 ‥ 185.73) │ void cutlass::Kernel2<cutlass_80_tensorop_d884gemm_64x32_16x4_nn_align1>(cutlass_80_tensorop_d884gemm_64x32_16x4_nn_align1::Params)                                                                                                                                                                                                                                                 │\n",
       "│    0.06% │    8.11 µs │     6 │   1.35 µs ± 0.19   (  1.19 ‥ 1.67)   │ [copy pageable to device memory]                                                                                                                                                                                                                                                                                                                                                    │\n",
       "└──────────┴────────────┴───────┴──────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "\n",
       "NVTX ranges:\n",
       "┌──────────┬────────────┬───────┬─────────────────────────────────────┬─────────────────────────┐\n",
       "│\u001b[1m Time (%) \u001b[0m│\u001b[1m Total time \u001b[0m│\u001b[1m Calls \u001b[0m│\u001b[1m Time distribution                   \u001b[0m│\u001b[1m Name                    \u001b[0m│\n",
       "├──────────┼────────────┼───────┼─────────────────────────────────────┼─────────────────────────┤\n",
       "│   60.31% │\u001b[31m    7.89 ms \u001b[0m│     3 │   2.63 ms ± 0.07   (  2.58 ‥ 2.71)  │\u001b[1m Main.Naive Matmul       \u001b[0m│\n",
       "│   32.08% │     4.2 ms │     3 │    1.4 ms ± 0.02   (  1.38 ‥ 1.41)  │ Main.Coalesced Matmul   │\n",
       "│    7.50% │  981.33 µs │     3 │ 327.11 µs ± 40.79  (297.31 ‥ 373.6) │ Main.LinearAlgebra.mul! │\n",
       "└──────────┴────────────┴───────┴─────────────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let\n",
    "    N = 1024\n",
    "    R = 512\n",
    "    M = 2048\n",
    "    T = Float64\n",
    "    A = rand!(allocate(backend, T, N, R))\n",
    "    B = rand!(allocate(backend, T, R, M))\n",
    "    output_naive = KernelAbstractions.zeros(backend, T, N, M)\n",
    "    output_coalesced = KernelAbstractions.zeros(backend, T, N, M)\n",
    "    output_mul = KernelAbstractions.zeros(backend, T, N, M)\n",
    "\n",
    "\n",
    "    CUDA.@profile for _ in 1:nreps\n",
    "      NVTX.@range \"Naive Matmul\" begin\n",
    "          naive_matmul!(output_naive, A, B)\n",
    "          KernelAbstractions.synchronize(backend)\n",
    "      end\n",
    "\n",
    "      NVTX.@range \"Coalesced Matmul\" begin\n",
    "          coalesced_matmul!(output_coalesced, A, B)\n",
    "          KernelAbstractions.synchronize(backend)\n",
    "      end\n",
    "\n",
    "      NVTX.@range \"LinearAlgebra.mul!\" begin\n",
    "          LinearAlgebra.mul!(output_mul, A, B)\n",
    "          KernelAbstractions.synchronize(backend)\n",
    "      end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "1.11.4 (16-threads) 1.11.4",
   "language": "julia",
   "name": "1.11.4-_16-threads_-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
